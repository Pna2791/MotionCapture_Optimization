# Transformer Inertial Poser (TIP): Real-time Human Motion Reconstruction from Sparse IMUs with Simultaneous Terrain Generation

This is the Python implementation accompanying our TIP paper at SIGGRAPH Asia 2022.

Arxiv: https://arxiv.org/abs/2203.15720

Video: https://youtu.be/rXb6SaXsnc0

Copyright 2022 Meta Inc. and Stanford University

Licensed under the CC-BY-NC-4.0 License

![TIP Teaser](data/tip.png)

## Environment Setup

(Only tested on Ubuntu 18.04; Might work on Windows with some minor modifications)

1.Go to (https://www.anaconda.com/download/) and install the Python 3 version of Anaconda or Miniconda.

2.Open a new terminal and run the following commands to create a new conda environment (https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html):

```conda create -n tip22 python=3.8```

3.Activate & enter the new environment you just creared:

```conda activate tip22```

4.Inside the new environment, and inside the project directory:

```pip install -r requirements.txt```

5.Install pytorch with CUDA (only tested with the following version, should work with other versions though):

```conda install pytorch==2.1.1 cudatoolkit=11.8 -c pytorch -c conda-forge``` 	(check pytorch website for your favorite version)

6.Install our fork of the Fairmotion library, at a location you prefer:
```
git clone https://github.com/jyf588/fairmotion.git
cd fairmotion
pip install -e .
```

## Datasets and Models

### AMASS

Download AMASS from https://amass.is.tue.mpg.de/download.php. ```SMPL+H``` is the file format we use, though no hand motions are generated by our algorithm. 

We only used a couple of subsets within AMASS to train the model; including more data synthesized from AMASS might improve performance, but we have not tried it. Decompress the datasets and place these folders ```AMASS_CMU, KIT, Eyes_Japan_Dataset, HUMAN4D, ACCAD, DFaust_67, HumanEva, MPI_Limits, MPI_mosh, SFU, Transitions_mocap, TotalCapture, DanceDB``` inside ```data/source/```

## Data Processing and Training
